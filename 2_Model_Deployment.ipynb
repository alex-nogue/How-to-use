{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model deployment\n",
    "\n",
    "This notebook explains how to deploy the model that we have trained and registered in an Azure workspace in the previous notebook. The model will be deployed as a web service in [Azure Container Instances](https://docs.microsoft.com/en-gb/azure/container-instances/).\n",
    "\n",
    "A web service is an image, in this case a Docker image. It encapsulates the scoring logic and the model itself. This image is what will later be called in Power BI.\n",
    "\n",
    "To build the correct environment for Container Instances, provide the following components:\n",
    "\n",
    "- A scoring script to show how to use the model.\n",
    "- An environment file to show what packages need to be installed.\n",
    "- A configuration file to build the container instance.\n",
    "- The model we trained in the previous notebook.\n",
    "\n",
    "This section is mainly based on the following link: https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the model from the Workspace\n",
    "\n",
    "Before deploting the model, we should first download it from the Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33206, st_ino=9851624185204729, st_dev=270394477, st_nlink=1, st_uid=0, st_gid=0, st_size=637, st_atime=1568707412, st_mtime=1568707948, st_ctime=1568619226)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the model from the workspace\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "ws = Workspace.from_config()\n",
    "model = Model(ws, 'diabetes_regression')\n",
    "\n",
    "model.download(target_dir=os.getcwd(), exist_ok=True)\n",
    "\n",
    "# verify the downloaded model file\n",
    "file_path = os.path.join(os.getcwd(), \"diabetes_regression.pkl\")\n",
    "\n",
    "os.stat(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a scoring script\n",
    "\n",
    "The scoring script contains the instructions to deploy the model as a web service. It must include the two following functions:\n",
    "\n",
    "- ```python\n",
    "init()\n",
    "```  \n",
    "Loads the model saved in the Workspace into a global object.\n",
    "- ```\n",
    "run(input_data)\n",
    "```\n",
    "Uses the model to make predictions based on the input data.\n",
    "\n",
    "In addition, the scoring script must provide instructions to AML to generate a schema file. A schema file is what is going to tell Power BI what is expected as input and what is going to be returned by the model. In other words, the scoring script must provide a sample of the input and output of the deployed model. See this links to have futher information on schema generation [link1](https://docs.microsoft.com/en-us/power-bi/service-machine-learning-integration), [link2](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where#example-script-with-dictionary-input-support-consumption-from-power-bi). This step is very important as Power BI won't be able to invoke a model without schema.\n",
    "\n",
    "Note that schema generation is note required for model deployment but it is for invoking the deployed web service in Power BI. If you deploy a web service with AML Studio, the schema generation is automatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "# Create a scoring script\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # retrieve the path to the model file using the model name\n",
    "    model_path = Model.get_model_path('diabetes_regression')\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "# Schema generation\n",
    "# Must be set in the scoring script, out of the init() and run() functions.\n",
    "# In our case, we have a dataframe as input with 10 variables: 0 to 9 and they are all numeric.\n",
    "input_sample = pd.DataFrame(data=[{\n",
    "    \"0\": 0.1,\n",
    "    \"1\": 0.1,\n",
    "    \"2\": 0.1,\n",
    "    \"3\": 0.1,\n",
    "    \"4\": 0.1,\n",
    "    \"5\": 0.1,\n",
    "    \"6\": 0.1,\n",
    "    \"7\": 0.1,\n",
    "    \"8\": 0.1,\n",
    "    \"9\": 0.1\n",
    "}])\n",
    "\n",
    "# As our model is a regression, the output is numeric and, in our case, the model returns an array.\n",
    "# Check the type of your input and output to specify the correct format of your input and output sample.\n",
    "output_sample = np.array([241.1])\n",
    "\n",
    "# Specify the type of your input and output\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample)) \n",
    "\n",
    "def run(data):\n",
    "    # make prediction\n",
    "    y_hat = model.predict(data)\n",
    "    # you can return any data type as long as it is JSON-serializable\n",
    "    return y_hat.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment file\n",
    "\n",
    "We create an environment file, called _myenv.yml_, that specifies all of the script's package dependencies. This file is used to make sure that all of those dependencies are installed in the Docker image.\n",
    "\n",
    "This file can be created via Python code (follow the instrctions [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml)) but as I particularly struggled to include the __inference_schema__ library, I used the file _myenv.yml_ saved in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the environment file\n",
    "# from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# myenv = CondaDependencies()\n",
    "# myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# with open(\"myenv.yml\", \"w\") as f:\n",
    "#     f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a configuration file\n",
    "\n",
    "Create a deployment configuration file. Specify the number of CPUs and gigabytes of RAM needed for your Container Instances container. The cost and time of execution will then be affected by the configuration.\n",
    "\n",
    "Here we used a 1 code and 1 Gb RAM, as for our simple use case, it is more han enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration file\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"Diabetes_data\",  \n",
    "                                                     \"method\": \"sklearn\"},\n",
    "                                               description='Predict diabetes with sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as a web service\n",
    "\n",
    "Once we have all required files, we can now deploy our model. We are now going to:\n",
    "- Build an image by using these files:\n",
    "   - The scoring file, _score.py_\n",
    "   - The environment file, _myenv.yml_\n",
    "   - The model file\n",
    "- Register the image under the workspace.\n",
    "- Send the image to the Container Instances container.\n",
    "- Start up a container in Container Instances by using the image.\n",
    "- Get the web service HTTP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running..............................................................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Deploy in container instances\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\")\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name='diabetes-regression',\n",
    "                       models=[model], \n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have deployed a web service and it is ready to use in other applications. You could test whether the web service has been deployed correctly following the section __Test the deployed serice__ from this [link](https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml#test-the-model-locally). \n",
    "\n",
    "We are now going to invoke this model in Power BI, in the notebook __3_Invoke_the_model_in_Power_BI__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember you hve a resource group and a Container Instance services running, so that it might incur in costs in your Subscription. If you want to delete it, use the following cell to delete the service and go to the Azure portal to delete the resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
